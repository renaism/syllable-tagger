{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "import training.preprocess as preprocess\n",
    "import testing.tagger as tagger\n",
    "import testing.syllabification as syllabification\n",
    "import config\n",
    "import testing.stemmer as stemmer\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import result data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../../data/g2p/var/test/20201214222029_rules_stem_gkn_n=7_B=15_fold_1.txt\"\n",
    "\n",
    "res_data = pd.read_csv(\n",
    "    fpath,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['word', 'syllables', 'prediction', 'mmc'],\n",
    "    na_filter=False\n",
    ")\n",
    "res_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong phoneme frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_phonemes = []\n",
    "wrong_phonemes_dict = {}\n",
    "\n",
    "for row in res_data.itertuples():\n",
    "    if row.mmc == 0:\n",
    "        wrong_phonemes.append(\"-\")\n",
    "    else:\n",
    "        wp_string = \"\"\n",
    "        c = 0\n",
    "        for i in range(len(row.syllables)):\n",
    "            if row.syllables[i] != row.prediction[i]:\n",
    "                wp = f\"{row.syllables[i]}/{row.prediction[i]}\"\n",
    "                wp_string += wp\n",
    "\n",
    "                if wp not in wrong_phonemes_dict:\n",
    "                    wrong_phonemes_dict[wp] = 0\n",
    "                wrong_phonemes_dict[wp] += 1\n",
    "\n",
    "                c += 1\n",
    "\n",
    "                if c < row.mmc:\n",
    "                    wp += \" \"\n",
    "\n",
    "        wrong_phonemes.append(wp_string)\n",
    "\n",
    "res_data_new = res_data.copy()\n",
    "res_data_new[\"wrong_phonemes\"] = wrong_phonemes\n",
    "\n",
    "freq_data_list = []\n",
    "\n",
    "for phonemes_str, freq in wrong_phonemes_dict.items():\n",
    "    phonemes = phonemes_str.split(\"/\")\n",
    "    freq_data_list.append((phonemes[0], phonemes[1], freq))\n",
    "\n",
    "freq_data = pd.DataFrame(freq_data_list, columns=[\"real_phoneme\", \"pred_phoneme\", \"frequency\"]).sort_values(\"frequency\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "freq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../../data/g2p/var/test/wfp_b=15_fold_1.txt\"\n",
    "\n",
    "freq_data.to_csv(\n",
    "    fpath,\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    header=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error source frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_types = []\n",
    "wrong_types_dict = {\"affix\": 0, \"root\": 0, \"both\": 0}\n",
    "\n",
    "st = stemmer.Stemmer()\n",
    "\n",
    "for row in res_data.itertuples():\n",
    "    if row.mmc == 0:\n",
    "        wrong_types.append(\"-\")\n",
    "    else:\n",
    "        prefix, root, d_suffix, i_suffix = st.getRoot(row.word)\n",
    "\n",
    "        if prefix == '' and d_suffix == '' and i_suffix == '':\n",
    "            wrong_types.append(\"root\")\n",
    "            wrong_types_dict[\"root\"] += 1\n",
    "            continue\n",
    "        \n",
    "        affix = False\n",
    "        root = False\n",
    "\n",
    "        for i in range(len(row.syllables)):\n",
    "            if row.syllables[i] != row.prediction[i]:\n",
    "                if i >= len(prefix) and i < (len(row.word) - len(d_suffix) - len(i_suffix)):\n",
    "                    root = True\n",
    "                else:\n",
    "                    affix = True\n",
    "            \n",
    "        if affix and root:\n",
    "            wrong_types.append(\"both\")\n",
    "            wrong_types_dict[\"both\"] += 1\n",
    "        elif affix:\n",
    "            wrong_types.append(\"affix\")\n",
    "            wrong_types_dict[\"affix\"] += 1\n",
    "        else:\n",
    "            wrong_types.append(\"root\")\n",
    "            wrong_types_dict[\"root\"] += 1\n",
    "\n",
    "res_data_new = res_data.copy()\n",
    "res_data_new[\"wrong_types\"] = wrong_types\n",
    "\n",
    "pprint(wrong_types_dict)\n",
    "print(f\"Total word error: {sum(wrong_types_dict[x] for x in wrong_types_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../../data/g2p/var/wrong_types_vanilla.txt\"\n",
    "\n",
    "res_data_new.to_csv(\n",
    "    fpath,\n",
    "    sep='\\t', \n",
    ")"
   ]
  }
 ]
}