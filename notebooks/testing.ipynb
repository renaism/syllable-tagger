{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules['src.testing.probability'])\n",
    "importlib.reload(sys.modules['src.testing.tagger'])\n",
    "importlib.reload(sys.modules['src.testing.syllabification'])\n",
    "importlib.reload(sys.modules['src.utility'])\n",
    "importlib.reload(sys.modules['src.ngram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import time\n",
    "import pandas as pd\n",
    "import src.utility as util\n",
    "import src.testing.probability as probability\n",
    "import src.testing.tagger as tagger\n",
    "import src.testing.syllabification as syllabification\n",
    "import src.ngram as ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllabify_folds(n, prob_args, fnames, state_elim=True, k_min=1, k_max=5, n_sample=None, sample_seed=0, cache_preload=None, log_fname='', fname_param='method', save_log=True, save_result=False, save_result_timestamp=True, save_cache=False, validation=True):\n",
    "    start_t = time.time()\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    results = {\n",
    "        'metadata': {\n",
    "            'n': n,\n",
    "            'k_min': k_min,\n",
    "            'k_max': k_max,\n",
    "            'state_elim': state_elim,\n",
    "            'n_sample': n_sample,\n",
    "            'sample_seed': sample_seed,\n",
    "            'prob_args': prob_args.copy()\n",
    "        },\n",
    "        'fold_results': {}\n",
    "    }\n",
    "\n",
    "    util.print_dict(results['metadata'])\n",
    "\n",
    "    for fold in range(k_min, k_max+1):\n",
    "        data_test_fname = '{}_fold_{}.txt'.format(fnames['data_test'], fold)\n",
    "        n_gram_fname = '{}_fold_{}.json'.format(fnames['n_gram'], fold)\n",
    "\n",
    "        print('Fold        : {}'.format(fold))\n",
    "        print('Data test   : \"{}\"'.format(data_test_fname))\n",
    "        print('n-gram      : \"{}\"'.format(n_gram_fname))\n",
    "\n",
    "        if 'with_aug' in prob_args and prob_args['with_aug']:\n",
    "            n_gram_aug_fname = '{}_fold_{}.json'.format(fnames['n_gram_aug'], fold)\n",
    "            print('n-gram aug  : \"{}\"'.format(n_gram_aug_fname))\n",
    "\n",
    "        data_test = pd.read_csv(\n",
    "            data_test_fname, \n",
    "            sep='\\t', \n",
    "            header=None,\n",
    "            names=['word', 'syllables'] if validation else ['word'],\n",
    "            na_filter=False\n",
    "        )\n",
    "\n",
    "        print('Total words : {}'.format(len(data_test)))\n",
    "\n",
    "        if n_sample != None:\n",
    "            data_test = data_test.sample(n=n_sample, random_state=sample_seed).reset_index(drop=True)\n",
    "\n",
    "        prob_args['n_gram'] = ngram.load(n_gram_fname, n_max=n, load_follow_fdist=True, load_cont_fdist=True)\n",
    "        \n",
    "        if prob_args['with_cache']:\n",
    "            if cache_preload != None and 'cache' in cache_preload:\n",
    "                prob_args['cache'] = probability.load_cache('{}_fold_{}.json'.format(cache_preload['cache'], fold), '../data/cache/')\n",
    "            else:\n",
    "                prob_args['cache'] = probability.generate_prob_cache(n)\n",
    "                \n",
    "\n",
    "        if prob_args['method'] == 'gkn':\n",
    "            prob_args['d_cache'] = probability.generate_gkn_discount_cache(n, prob_args['n_gram'], prob_args['d_ceil'])\n",
    "\n",
    "        if prob_args['with_aug']:\n",
    "            prob_args['n_gram_aug'] = ngram.load(n_gram_aug_fname, n_max=n, load_follow_fdist=True, load_cont_fdist=True)\n",
    "\n",
    "            if prob_args['with_cache']:\n",
    "                if cache_preload != None and 'cache_aug' in cache_preload:\n",
    "                    prob_args['cache_aug'] = probability.load_cache('{}_fold_{}.json'.format(cache_preload['cache_aug'], fold), '../data/cache/')\n",
    "                else:\n",
    "                    prob_args['cache_aug'] = probability.generate_prob_cache(n)\n",
    "                    \n",
    "\n",
    "            if prob_args['method'] == 'gkn':\n",
    "                prob_args['d_cache_aug'] = probability.generate_gkn_discount_cache(n, prob_args['n_gram_aug'], prob_args['d_ceil'])\n",
    "\n",
    "        result = syllabification.syllabify(data_test, n, prob_args, validation=validation)\n",
    "        results['fold_results'][fold] = result['metadata']\n",
    "\n",
    "        if save_result:\n",
    "            syllabification.save_result(result['data'], '{}_{}={}_fold_{}.txt'.format(log_fname, fname_param, prob_args[fname_param], fold), folder=fnames['result_folder'], with_timestamp=save_result_timestamp)\n",
    "        \n",
    "        if save_cache:\n",
    "            if 'cache' in prob_args:\n",
    "                probability.save_cache(prob_args['cache'], 'cache_prob_{}_{}={}_fold_{}.json'.format(log_fname, fname_param, prob_args[fname_param], fold), '../data/cache/')\n",
    "            if 'cache_aug' in prob_args:\n",
    "                probability.save_cache(prob_args['cache_aug'], 'cache_aug_prob_{}_{}={}_fold_{}.json'.format(log_fname, fname_param, prob_args[fname_param], fold), '../data/cache/')\n",
    "\n",
    "        # Clear n_gram from memory\n",
    "        prob_args['n_gram'] = None\n",
    "        prob_args['n_gram_aug'] = None\n",
    "\n",
    "        print('\\n')\n",
    "    \n",
    "    end_t = time.time()\n",
    "    avg_ser = sum(results['fold_results'][i]['syllable_error_rate'] for i in range(k_min, k_max+1)) / (k_max-k_min+1)\n",
    "    results['metadata']['average_ser'] = round(avg_ser, 5)\n",
    "    results['metadata']['start_time'] = time.strftime('%Y/%m/%d - %H:%M:%S', time.localtime(start_t))\n",
    "    results['metadata']['end_time'] = time.strftime('%Y/%m/%d - %H:%M:%S', time.localtime(end_t))\n",
    "    results['metadata']['duration'] = round(end_t - start_t, 2)\n",
    "    \n",
    "    if save_log:\n",
    "        log_fname += '_' if log_fname != '' else ''\n",
    "        util.save_dict_to_log(results, '{}_{}={}.log'.format(log_fname, fname_param, prob_args[fname_param]), '../logs/')\n",
    "\n",
    "    print('Finished in {:.2f} s'.format(end_t - start_t))\n",
    "\n",
    "    return results, prob_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aug_w in [None]:\n",
    "    prob_args = {\n",
    "        'method': 'gkn',\n",
    "        'd_ceil': 3,\n",
    "        'with_cache': True,\n",
    "        'with_aug': False,\n",
    "        'aug_w': aug_w,\n",
    "        'n': 4\n",
    "    }\n",
    "\n",
    "    fnames = {\n",
    "        'data_test': '../data/testset/named-entity/test_mne_20k',\n",
    "        'n_gram':  '../models/ngrams/named-entity/5_gram_mne_20k',\n",
    "        'n_gram_aug': '../models/ngrams/named-entity/5_gram_ne_aug',\n",
    "        'result_folder': '../data/results/named-entity/m/'\n",
    "    }\n",
    "\n",
    "    result, post_prob_args = syllabify_folds(\n",
    "        n=4,        \n",
    "        prob_args=prob_args,\n",
    "        fnames=fnames, \n",
    "        k_min=1, k_max=1,\n",
    "        log_fname='gkn_n=4',\n",
    "        fname_param='d_ceil',\n",
    "        save_log=True,\n",
    "        save_result=True,        \n",
    "        save_result_timestamp=False,\n",
    "        save_cache=False,\n",
    "        validation=False\n",
    "    )\n",
    "\n",
    "    print()"
   ]
  }
 ]
}